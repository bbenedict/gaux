# GAUX

## Generative Ai User eXperience (GAUX)

pronunciation:  _"go x" or "go experience"_

How do we evaluate the user experience of Generative AI?  Is it enough to just by amazed by the capabilities or do we need to start paying attention to other factors?  This new area of computer functionality has some unique aspects.  For example, when have you ever had to be concerned if the software you were using was making something up? That's a far distance from inaccurate data or invalid search results.

We can look at the GAUX experience across five factors that ultimately determine if the user is having a good and productive experience using Generative AI.  This list includes expected factors like did the system effectively complete the task and in reasonable time.  Also included are factors unique to Generative AI like hallucination.  The user should be having a good experience if the response is effective and not fake or biased. This site is a collection of links, articles and code to help better understand the GAUX experience.


## Factors of GUAX

### accuracy <span style="font-size:12px;margin-left:10px">[read more](ACCURACY.md)</span>

How correct or accurate was the information?  For example, was the meeting summary a good representation of the meeting?  Was the generated image a good representation of the request?

### hallucination <span style="font-size:12px;margin-left:10px">[read more](HALLUCINATION.md)</span>

Was anything in the response fabricated or made up?  Is there a topic in the meeting summary that was never actually discussed? Does the image have distortions that don't correlate with example images?

### bias <span style="font-size:12px;margin-left:10px">[read more](BIAS.md)</span>

Did the response contain any inherent bias? Was it a fair response?

### performance <span style="font-size:12px;margin-left:10px">[read more](PERFORMANCE.md)</span>

How long did it take to complete the request?  Is that a reasonable amount of time?

### effectiveness <span style="font-size:12px;margin-left:10px">[read more](EFFECTIVENESS.md)</span>

Was the generated output effective at the requested task?  For example, is it a precise summarization or is it too long to be helpful? Is the generated image creative or does it look like an amateur artist created it? Effectivenes is heavily influenced by max tokens, temperature and other LLM settings.

## Information on user experience and metrics

[Choosing a metric for your task -- HuggingFace.co](https://huggingface.co/docs/evaluate/choosing_a_metric)  
[Generative AI: How do we measure success? -- LinkedIn](https://www.linkedin.com/pulse/generative-ai-how-do-we-measure-success-mj-petroni/)  
[Evaluating LLM Applications -- HumanLoop](https://humanloop.com/blog/evaluating-llm-apps)  
[How to Evaluate LLMs: A Complete Metric Framework -- Microsoft](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/)  
