# Hallucination

Hallucination with text generation and LLMs happens when the LLM includes output that is false or completely made up. The article, "Mitigating LLM Hallucinations: a multifaceted approach" by Xavier (Xavi) Amatriain, mentions the Merriam-Webster dictionary characterizes LLM hallucination as “a plausible but false or misleading response generated by an artificial intelligence algorithm.”  

How can we detect hallucinations?  In the book, "The AI Revolution in Medicine", by Peter Lee, Carey Goldberg, and Issac Kohane, the authors provide one idea to detect halllucination by simply asking the LLM to verify the information is factual.  Below is an example from the book.  The AI has fabricated educational credentials as part of a response.

<div style="padding-left:40px;padding-right:40px;margin-bottom:20px">
Question to LLM: Can you check this conversation between a human and an AI-powered chatbot for errors?</br> 
Reply from LLM: It appears that there is an error in the AI’s response. AI-powered chatbots do not have personal experiences or educational backgrounds like humans do.
</div><br>  

Another way to check for hallucination is using the FActScore approach. We use an LLM to break the output into specific facts.  We then use an LLM to determine if each fact is true or false.  The example code illustrates how this is done.  Use the following commands to run the example. You only need to run the install command the first time. Python 3.10 is required. 

```
pipenv install
pipenv run python src/hallucination.py
```

There are two examples in the code in src/hallucination.py.  The first example provides facts about the sun.  The second example provides mostly ridiculous facts about baseball.  Below is typical output.

```
Score: 1.0,   Content: Yes, the sun is extremely hot. Its surface temperature is
              about 5,500 degrees Celsius (9,932 degrees Fahrenheit). Inside the
              sun at its core, temperatures reach approximately 15 million degrees
              Celsius (27 million degrees Fahrenheit).

Score: 0.25,  Content: Baseball is played with a large telescope.  Baseball players use a
              bat to hit a ball. There are 2 adults and 5 children in each game
              and the game takes one week to play.
```

## Resources

[Understanding Hallucinations in AI: A Comprehensive Guide](https://www.pinecone.io/learn/ai-hallucinations/)  
[What are AI hallucinations?](https://www.ibm.com/topics/ai-hallucinations)  
[Mitigating LLM Hallucinations: a multifaceted approach](https://amatriain.net/blog/hallucinations)  
[Survey of Hallucination in Natural Language Generation](https://arxiv.org/abs/2202.03629)  
[FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://arxiv.org/abs/2305.14251)  
